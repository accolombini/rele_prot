# üîß Issues Pendentes - ProtecAI

## üö® CR√çTICO

### Issue #1: Carregamento de Par√¢metros no Banco de Dados
**Status**: ‚è≥ **BLOQUEADOR**
**Descoberto em**: 20/11/2025
**Impacto**: 3947 par√¢metros extra√≠dos, 0 no banco de dados

#### Descri√ß√£o
O sistema extrai 3947 par√¢metros corretamente e normaliza em `all_parameters.csv`, mas n√£o consegue carreg√°-los no PostgreSQL devido a incompatibilidade de chaves estrangeiras.

#### Causa Raiz
- **Tabela `parameters`** espera FK: `protection_function_id` (INT)
- **CSV `all_parameters.csv`** fornece: `relay_id` (VARCHAR, ex: "R001")
- **Problema**: N√£o h√° mapeamento direto entre par√¢metros e fun√ß√µes de prote√ß√£o

#### Dados Atuais
```
Extra√≠dos: 3947 par√¢metros
No Banco: 0 par√¢metros
Perda: 100%
```

#### Op√ß√µes de Solu√ß√£o

##### Op√ß√£o A: Criar Tabela `relay_parameters` (Recomendada)
**Descri√ß√£o**: Criar tabela separada para par√¢metros n√£o vinculados a prote√ß√µes
```sql
CREATE TABLE protec_ai.relay_parameters (
    id SERIAL PRIMARY KEY,
    relay_id INTEGER REFERENCES protec_ai.relays(id),
    parameter_code VARCHAR(50),
    parameter_name TEXT,
    parameter_value TEXT,
    unit VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```
**Vantagens**:
- Arquitetura limpa
- Par√¢metros de sistema separados de par√¢metros de prote√ß√£o
- Permite futura expans√£o (par√¢metros globais vs espec√≠ficos)

**Desvantagens**:
- Requer migra√ß√£o do schema
- Duas tabelas para par√¢metros

**Tempo**: 1-2 horas

##### Op√ß√£o B: Mapear para Primeira Prote√ß√£o
**Descri√ß√£o**: Associar todos os par√¢metros √† primeira fun√ß√£o de prote√ß√£o do rel√©
```python
# Buscar primeira prote√ß√£o do rel√©
first_protection = session.query(ProtectionFunction)\
    .filter_by(relay_id=relay_db_id).first()
if first_protection:
    parameter.protection_function_id = first_protection.id
```
**Vantagens**:
- R√°pido de implementar
- N√£o requer mudan√ßa de schema

**Desvantagens**:
- Semanticamente incorreto (par√¢metros n√£o pertencem a prote√ß√µes espec√≠ficas)
- Dados artificialmente vinculados

**Tempo**: 30 minutos

##### Op√ß√£o C: Criar Prote√ß√£o Gen√©rica "System Parameters"
**Descri√ß√£o**: Criar fun√ß√£o de prote√ß√£o virtual para cada rel√©
```python
# Criar prote√ß√£o gen√©rica se n√£o existir
system_protection = ProtectionFunction(
    relay_id=relay_db_id,
    function_name="System Parameters",
    ansi_function_id=ansi_unknown_id
)
```
**Vantagens**:
- Mant√©m arquitetura atual
- Separa√ß√£o clara (prote√ß√£o virtual vs reais)

**Desvantagens**:
- Polui√ß√£o de dados (prote√ß√µes "fake")
- Confus√£o em relat√≥rios

**Tempo**: 1 hora

#### Decis√£o Necess√°ria
‚è≥ **Aguardando decis√£o do usu√°rio/arquiteto**

#### Workaround Tempor√°rio
Par√¢metros permanecem em `all_parameters.csv` at√© decis√£o. Relat√≥rios podem ler diretamente do CSV.

---

## ‚ö†Ô∏è ALTA PRIORIDADE

### Issue #2: C√≥digos ANSI "Unknown"
**Status**: ‚è≥ N√£o Implementado
**Impacto**: 77 prote√ß√µes sem identifica√ß√£o ANSI correta

#### Descri√ß√£o
Todas as prote√ß√µes est√£o sendo marcadas como ANSI "Unknown" porque os parsers n√£o extraem c√≥digos ANSI dos nomes das fun√ß√µes.

#### Exemplos
```csv
Relay ID,Function Name,ANSI Code
R002,50N-1 NEF I>,Unknown
R003,Directional O/C Ph,Unknown
R006,67N-1 Directional EF,Unknown
```

#### Causa Raiz
- **Parsers atuais**: Extraem nome da prote√ß√£o, mas n√£o identificam ANSI code
- **Gloss√°rio ANSI**: N√£o implementado
- **Regex patterns**: N√£o buscam c√≥digos ANSI (50, 51, 67N, etc.)

#### Dados Atuais
```
Total prote√ß√µes: 77
Com c√≥digo ANSI: 0
"Unknown": 77 (100%)
```

#### Solu√ß√£o Proposta

##### Fase 1: Criar Gloss√°rio ANSI
**Arquivo**: `inputs/glossario/ansi_codes.json`
```json
{
  "50": {"description": "Instantaneous Overcurrent", "type": "Phase"},
  "50N": {"description": "Instantaneous Ground Overcurrent", "type": "Ground"},
  "51": {"description": "Time Overcurrent", "type": "Phase"},
  "51N": {"description": "Time Ground Overcurrent", "type": "Ground"},
  "67": {"description": "Directional Overcurrent", "type": "Phase"},
  "67N": {"description": "Directional Ground Overcurrent", "type": "Ground"},
  "87": {"description": "Differential Protection", "type": "Differential"},
  ...
}
```

##### Fase 2: Melhorar Parsers
**Arquivos**: `micon_parser.py`, `sepam_parser.py`, `schneider_parser.py`
```python
import re

ANSI_PATTERN = re.compile(r'\b(\d{2}[A-Z]?)\b')

def extract_ansi_code(function_name):
    """Extrai c√≥digo ANSI do nome da fun√ß√£o"""
    match = ANSI_PATTERN.search(function_name)
    if match:
        return match.group(1)
    return "Unknown"
```

##### Fase 3: Atualizar Normalizadores
**Arquivo**: `normalize.py`
```python
# Adicionar coluna ANSI code
protections_df['ansi_code'] = protections_df['function_name'].apply(extract_ansi_code)
```

**Tempo Estimado**: 4-6 horas

#### Impacto nos Relat√≥rios
- ‚ö†Ô∏è Relat√≥rio de prote√ß√µes ter√° campos vazios
- ‚ö†Ô∏è Imposs√≠vel filtrar/agrupar por tipo de prote√ß√£o
- ‚ö†Ô∏è An√°lise comparativa de prote√ß√µes limitada

---

## üìä M√âDIA PRIORIDADE

### Issue #3: Performance com Grandes Volumes
**Status**: ‚è≥ N√£o Testado
**Impacto Potencial**: Alto com 42+ rel√©s

#### Descri√ß√£o
Pipeline atual processa 8 rel√©s em 3.2 segundos. Performance com 50 rel√©s n√£o foi testada.

#### Previs√£o
```
8 rel√©s: 3.2s
50 rel√©s: ~20s (estimativa linear)
100 rel√©s: ~40s
```

#### Gargalos Potenciais
1. **Extra√ß√£o PDF**: PyMuPDF l√™ arquivo completo em mem√≥ria
2. **Normaliza√ß√£o**: Concatena√ß√£o de DataFrames sem otimiza√ß√£o
3. **Database Load**: Commits individuais sem batch

#### Solu√ß√µes Propostas

##### 3.1 Processamento Paralelo
```python
from concurrent.futures import ProcessPoolExecutor

def extract_file(file_path):
    # Extra√ß√£o de um arquivo
    pass

with ProcessPoolExecutor(max_workers=4) as executor:
    results = executor.map(extract_file, files)
```
**Ganho Esperado**: 2-4x mais r√°pido

##### 3.2 Batch Commits
```python
# Em vez de commit por rel√©
session.add(relay)
session.commit()

# Fazer batch
session.add_all(relays_list)
session.commit()
```
**Ganho Esperado**: 30-50% mais r√°pido

**Tempo Estimado**: 3-4 horas
**Prioridade**: Implementar ap√≥s teste com 42 rel√©s

---

### Issue #4: Falta de Interface Gr√°fica
**Status**: ‚è≥ Planejado para 21/11/2025
**Impacto**: Usu√°rio depende de linha de comando

#### Requisitos
- Dashboard com estat√≠sticas
- Execu√ß√£o de pipeline via web
- Upload de arquivos
- Gera√ß√£o de relat√≥rios
- Visualiza√ß√£o de rel√©s

**Ver**: `PLANO_TRABALHO_AMANHA.md` para detalhes

---

## üîç BAIXA PRIORIDADE

### Issue #5: Logs Muito Verbosos
**Status**: ‚è≥ Aceit√°vel por enquanto
**Impacto**: Arquivos de log grandes

#### Descri√ß√£o
Logs atuais s√£o muito detalhados (DEBUG level), gerando arquivos grandes.

#### Solu√ß√£o
```python
# Mudar n√≠vel de log em produ√ß√£o
logger.setLevel(logging.INFO)  # Em vez de DEBUG
```

**Tempo**: 15 minutos

---

### Issue #6: Sem Valida√ß√£o de Inputs
**Status**: ‚è≥ N√£o Cr√≠tico
**Impacto**: Erros n√£o informativos

#### Descri√ß√£o
Sistema n√£o valida arquivos antes de processar:
- Formato correto (PDF/TXT)
- Arquivo corrompido
- Fabricante desconhecido

#### Solu√ß√£o
```python
def validate_file(file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    
    if file_path.endswith('.pdf'):
        # Validar PDF
        pass
    elif file_path.endswith(('.txt', '.S40')):
        # Validar TXT
        pass
    else:
        raise ValueError(f"Unsupported format: {file_path}")
```

**Tempo**: 1-2 horas

---

### Issue #7: Falta de Testes Automatizados
**Status**: ‚è≥ Desej√°vel
**Impacto**: Risco de regress√µes

#### Descri√ß√£o
Nenhum teste automatizado implementado.

#### Proposta
```
tests/
‚îú‚îÄ‚îÄ test_extractors.py    # Testar extra√ß√£o de PDFs/TXT
‚îú‚îÄ‚îÄ test_parsers.py       # Testar parsers (MiCOM, SEPAM, Schneider)
‚îú‚îÄ‚îÄ test_normalizers.py   # Testar normaliza√ß√£o
‚îú‚îÄ‚îÄ test_loaders.py       # Testar carga no banco
‚îî‚îÄ‚îÄ test_reporters.py     # Testar gera√ß√£o de relat√≥rios
```

**Framework**: pytest
**Tempo**: 8-10 horas para cobertura completa

---

## üìà Roadmap

### Semana 1 (21-22/11/2025)
- [ ] **Issue #1**: Decidir e implementar solu√ß√£o de par√¢metros
- [ ] **Issue #4**: Implementar interface b√°sica Flask
- [ ] Testar com 42 novos rel√©s
- [ ] Gerar relat√≥rios completos

### Semana 2 (25-29/11/2025)
- [ ] **Issue #2**: Implementar identifica√ß√£o ANSI codes
- [ ] **Issue #3**: Testar performance, otimizar se necess√°rio
- [ ] **Issue #5**: Ajustar n√≠veis de log
- [ ] **Issue #6**: Implementar valida√ß√£o de inputs

### Semana 3 (02-06/12/2025)
- [ ] **Issue #7**: Implementar testes automatizados
- [ ] Documenta√ß√£o completa
- [ ] Deploy em ambiente de produ√ß√£o

---

## üîó Refer√™ncias

- [Plano de Trabalho Amanh√£](./PLANO_TRABALHO_AMANHA.md)
- [Sistema de Relat√≥rios](./SISTEMA_RELATORIOS.md)
- [README Principal](../README.md)
- [Database Schema](../docker/postgres/init.sql)
