# ProtecAI - Pipeline de ExtraÃ§Ã£o e AnÃ¡lise de RelÃ©s de ProteÃ§Ã£o

Sistema integrado para extraÃ§Ã£o, normalizaÃ§Ã£o e anÃ¡lise de dados de relÃ©s de proteÃ§Ã£o elÃ©trica.

## ðŸš€ ExecuÃ§Ã£o RÃ¡pida

### Pipeline Completa de Dados
```bash
workon rele_prot
python src/python/run_pipeline.py
```

Este comando Ãºnico executa todas as fases:
1. **ExtraÃ§Ã£o**: PDF/TXT â†’ CSV/Excel
2. **NormalizaÃ§Ã£o**: CSV â†’ Dados normalizados (3FN)
3. **Carga no Banco**: CSV normalizado â†’ PostgreSQL

### GeraÃ§Ã£o de RelatÃ³rios (On-Demand)
```bash
python src/python/generate_reports.py --all
```

## ðŸ“‹ PrÃ©-requisitos

- Python 3.12.5
- PostgreSQL 16 (via Docker)
- Ambiente virtual: `workon rele_prot`

### Iniciar Banco de Dados
```bash
docker-compose up -d
```

## ðŸ“‚ Estrutura do Projeto

```
inputs/
  â”œâ”€â”€ pdf/           # Arquivos PDF de relÃ©s
  â”œâ”€â”€ txt/           # Arquivos .S40 (SEPAM)
  â””â”€â”€ glossario/     # GlossÃ¡rios de mapeamento

outputs/
  â”œâ”€â”€ csv/           # CSVs extraÃ­dos
  â”œâ”€â”€ excel/         # Excel extraÃ­dos
  â”œâ”€â”€ norm_csv/      # Dados normalizados (5 arquivos consolidados)
  â””â”€â”€ norm_excel/    # Excel normalizados individuais

src/python/
  â”œâ”€â”€ run_pipeline.py       # ðŸŽ¯ COMANDO PRINCIPAL - Pipeline integrada
  â”œâ”€â”€ main.py              # FASE 1: ExtraÃ§Ã£o
  â”œâ”€â”€ normalize.py         # FASE 2: NormalizaÃ§Ã£o
  â”œâ”€â”€ test_loader.py       # FASE 3: Carga no banco
  â””â”€â”€ generate_reports.py  # RelatÃ³rios (separado)
```

## ðŸ”„ Fluxo da Pipeline

### 1ï¸âƒ£ ExtraÃ§Ã£o (main.py)
- **Input**: PDFs (GE MiCOM, Schneider Easergy) + TXT (.S40)
- **Processo**: ExtraÃ§Ã£o de parÃ¢metros, CTs, VTs, proteÃ§Ãµes
- **Output**: 8 CSVs + 8 Excel em `outputs/csv` e `outputs/excel`

### 2ï¸âƒ£ NormalizaÃ§Ã£o (normalize.py)
- **Input**: CSVs de `outputs/csv`
- **Processo**: NormalizaÃ§Ã£o para 3FN
- **Output**: 
  - 5 CSVs consolidados em `outputs/norm_csv/`:
    - `all_relays_info.csv`
    - `all_ct_data.csv`
    - `all_vt_data.csv`
    - `all_protections.csv`
    - `all_parameters.csv`
  - 8 Excel individuais em `outputs/norm_excel/`

### 3ï¸âƒ£ Carga no Banco (test_loader.py)
- **Input**: CSVs de `outputs/norm_csv`
- **Processo**: Carga no PostgreSQL (schema `protec_ai`)
- **Output**: Dados em tabelas relacionais

### ðŸ“Š RelatÃ³rios (generate_reports.py)
- **Input**: Dados do PostgreSQL
- **OpÃ§Ãµes**: 
  - `--all`: Todos os relatÃ³rios
  - `--relays`: InventÃ¡rio de relÃ©s
  - `--protections`: Resumo de proteÃ§Ãµes
- **Output**: CSV, Excel e PDF em `outputs/relatorios/`

## ðŸ”§ Arquivos Suportados

### Formatos
- **PDF**: GE MiCOM (00.01: format), Schneider Easergy (0120: format)
- **TXT**: SEPAM (.S40 files)

### Fabricantes
- General Electric (GE)
- Schneider Electric
- Alstom

## ðŸ“ˆ Exemplo de Uso

```bash
# 1. Ativar ambiente
workon rele_prot

# 2. Iniciar banco de dados
docker-compose up -d

# 3. Executar pipeline completa
python src/python/run_pipeline.py

# 4. Gerar relatÃ³rios (opcional)
python src/python/generate_reports.py --all
```

## ðŸŽ¯ Status Atual

âœ… **Funcionalidades Implementadas:**
- ExtraÃ§Ã£o de PDFs (GE + Schneider) e TXT (SEPAM)
- NormalizaÃ§Ã£o para 3FN
- Carga em PostgreSQL
- Pipeline integrada (comando Ãºnico)
- Sistema de relatÃ³rios on-demand

â³ **PrÃ³ximos Passos (21/11/2025):**
- Sistema de relatÃ³rios completo (5 relatÃ³rios principais)
- Interface web bÃ¡sica (Flask + Bootstrap)
- Teste com 42 novos relÃ©s
- Mapeamento de cÃ³digos ANSI

ðŸ“š **DocumentaÃ§Ã£o Detalhada:**
- [Plano de Trabalho 21/11](documentacao/PLANO_21NOV2025.md)
- [Arquitetura Front-end](documentacao/ARQUITETURA_FRONT_END.md)
- [Sistema de RelatÃ³rios](documentacao/SISTEMA_RELATORIOS.md)

## ðŸ“ Logs

Todos os logs sÃ£o salvos em `logs/` com timestamp:
- `pipeline_YYYYMMDD_HHMMSS.log` - Pipeline completa
- `extraction_YYYYMMDD_HHMMSS.log` - ExtraÃ§Ã£o
- `normalization_YYYYMMDD_HHMMSS.log` - NormalizaÃ§Ã£o
- `database_loader_YYYYMMDD_HHMMSS.log` - Carga no banco

## ðŸ› Troubleshooting

### VSCode travando
Use `workon rele_prot` em vez de `source /path/to/activate`

### Erro de conexÃ£o PostgreSQL
```bash
docker ps  # Verificar se container estÃ¡ rodando
docker-compose restart  # Reiniciar se necessÃ¡rio
```

### Reprocessar arquivos
```bash
echo '{"processed_files": {}}' > inputs/registry/processed_files.json
python src/python/run_pipeline.py
```
